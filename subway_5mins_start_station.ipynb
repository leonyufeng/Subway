{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import read_multiple_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_raw_trip_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_raw_trip_data:\n",
    "    trip_data = read_multiple_csv(\"./data/trip\")\n",
    "    trip_data.columns = ['event_id', 'start_station_id', 'start_time', 'end_station_id', 'end_time']\n",
    "    trip_data['start_time'] = pd.to_datetime(trip_data['start_time'], format=\"%Y-%m-%d-%H.%M.%S.000000\")\n",
    "    trip_data['end_time'] = pd.to_datetime(trip_data['end_time'], format=\"%Y-%m-%d-%H.%M.%S.000000\")\n",
    "#     trip_data['start_station_id'] = trip_data['start_station_id'].astype(int)\n",
    "#     trip_data['end_station_id'] = trip_data['end_station_id'].astype(int)\n",
    "else:\n",
    "    trip_data = pd.read_csv(\"processed_trip_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data['start_time'].min(), trip_data['start_time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_quarter(minute):\n",
    "#     if minute < 15:\n",
    "#         return 0.0\n",
    "#     elif 15 <= minute < 30:\n",
    "#         return 0.25\n",
    "#     elif 30 <= minute < 45:\n",
    "#         return 0.50\n",
    "#     elif 45 <= minute < 60:\n",
    "#         return 0.75\n",
    "    \n",
    "    \n",
    "def get_quarter(minute, split_mins=5):\n",
    "    time_block_no = minute // split_mins\n",
    "    return time_block_no*split_mins/60\n",
    "    \n",
    "    \n",
    "get_quarter(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data['start_date'] = trip_data['start_time'].dt.date\n",
    "trip_data['start_hour'] = trip_data['start_time'].dt.hour\n",
    "trip_data['start_min'] = trip_data['start_time'].dt.minute\n",
    "trip_data['end_date'] = trip_data['end_time'].dt.date\n",
    "trip_data['end_hour'] = trip_data['end_time'].dt.hour\n",
    "trip_data['end_min'] = trip_data['end_time'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data['start_quarter'] = trip_data['start_min'].apply(get_quarter)\n",
    "trip_data['start_hour_quarter'] = trip_data['start_hour'] + trip_data['start_quarter']\n",
    "# trip_data['end_quarter'] = trip_data['end_min'].apply(get_quarter)\n",
    "# trip_data['end_hour_quarter'] = trip_data['end_hour'].astype(str) + \"_\" + trip_data['end_quarter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_data['start_hour_min'] = trip_data['start_time'].dt.strftime('%H_%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_hour_func(hour):\n",
    "    if hour <= 4 or hour >= 23:\n",
    "        return 'mid_night'\n",
    "    else:\n",
    "        return str(hour)\n",
    "\n",
    "    \n",
    "# trip_data['start_hour'] = trip_data['start_hour'].apply(map_hour_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_count = trip_data[['event_id', 'start_date', 'start_station_id', 'start_hour']].groupby(\n",
    "#     ['start_station_id', 'start_date', 'start_hour']).agg('count')\n",
    "\n",
    "trip_count = trip_data[['event_id', 'start_date', 'start_station_id', 'start_hour_quarter']] \\\n",
    "                    .pivot_table(index=['start_station_id', 'start_date'],  \n",
    "                     columns='start_hour_quarter',\n",
    "                     values='event_id',\n",
    "                     fill_value=0, \n",
    "                     aggfunc='count').stack().to_frame()\n",
    "\n",
    "trip_count.columns = ['trip count']\n",
    "trip_count = trip_count.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count[trip_count['start_station_id']==446].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count['start_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count = trip_count[trip_count['start_date'].astype(str) >= '2016-01-01']\n",
    "trip_count.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data[['event_id', 'start_station_id', 'end_station_id', 'start_hour_quarter']].groupby(\n",
    "    ['start_station_id', 'end_station_id', 'start_hour_quarter']).agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv('./data/weather/weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_process_openweathermap(weather):\n",
    "    weather = weather.drop(['city_name', 'lat', 'lon', 'sea_level', 'grnd_level', 'snow_24h', 'snow_today', 'weather_icon', 'weather_id'], axis=1)\n",
    "    weather = weather.drop(['snow_1h', 'snow_3h'], axis=1)\n",
    "    weather = weather.fillna(0)\n",
    "\n",
    "    agg_funs = {'temp': 'mean', 'temp_min': 'min', 'temp_max': 'max', 'pressure':'mean', \n",
    "                'humidity': 'mean', 'wind_speed': 'mean', 'wind_deg': 'mean', \n",
    "                'rain_1h': 'mean', 'rain_3h': 'mean', 'rain_24h': 'mean', 'rain_today': 'mean',\n",
    "                'clouds_all': 'mean', 'weather_main': '|'.join, 'weather_description': '|'.join}\n",
    "\n",
    "    weather_unique = weather.groupby(['dt', 'dt_iso', 'city_id']).agg(agg_funs)\n",
    "    weather_unique = weather_unique.reset_index()\n",
    "\n",
    "    def kelvin_to_celsius(temperature):\n",
    "        return temperature - 273.15\n",
    "\n",
    "    weather_unique['temp'] = weather_unique['temp'].apply(kelvin_to_celsius)\n",
    "    weather_unique['temp_min'] = weather_unique['temp_min'].apply(kelvin_to_celsius)\n",
    "    weather_unique['temp_max'] = weather_unique['temp_max'].apply(kelvin_to_celsius)\n",
    "\n",
    "    weather_unique['datetime'] = pd.to_datetime(weather_unique['dt'], unit='s')\n",
    "    weather_unique['datetime'] = weather_unique['datetime'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "\n",
    "    weather_unique['date'] = weather_unique['datetime'].dt.date\n",
    "    weather_unique['hour'] = weather_unique['datetime'].dt.hour\n",
    "#     weather_unique['hour'] = weather_unique['hour'].apply(map_hour_func)\n",
    "    \n",
    "    return weather_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique = weather_process_openweathermap(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique = weather_unique[['city_id', 'temp', 'temp_min', 'temp_max', 'pressure',\n",
    "       'humidity', 'wind_speed', 'wind_deg', 'rain_1h', 'rain_3h', 'clouds_all', 'weather_main', 'weather_description', 'date', 'hour']].pivot_table(\n",
    "    index=['city_id', 'date'], columns='hour', values=['temp', 'temp_min', 'temp_max', 'pressure',\n",
    "       'humidity', 'wind_speed', 'wind_deg', 'rain_1h', 'rain_3h', 'clouds_all', 'weather_main', 'weather_description'], aggfunc=np.max, fill_value=1e9).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique.replace(1e9, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique = weather_unique.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique[weather_unique['date'].astype(str) >= '2016-01-01'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique['hour'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_unique.to_csv('weather_unique.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Date, weekend and Holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from chinese_calendar import is_workday, is_holiday\n",
    "\n",
    "april_last = datetime.date(2019, 5, 8)\n",
    "print(type(april_last))\n",
    "print(is_workday(april_last))\n",
    "print(is_holiday(april_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count['is_workday'] = trip_count['start_date'].apply(lambda d: is_workday(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count['start_date'] = pd.to_datetime(trip_count['start_date'], infer_datetime_format=True)\n",
    "trip_count['week_of_year'] = trip_count['start_date'].dt.week\n",
    "trip_count['weekday'] = trip_count['start_date'].dt.weekday\n",
    "trip_count['start_date'] = trip_count['start_date'].astype(str)\n",
    "trip_count['start_hour']  = trip_count['start_hour_quarter'].apply(np.floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count.columns = ['start_station_id', 'date', 'hour_quarter', 'trip_count',\n",
    "       'is_workday', 'week_of_year', 'weekday', 'hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_count['date'] = trip_count['date'].astype(str)\n",
    "trip_count['hour'] = trip_count['hour'].astype(int)\n",
    "weather_unique['date'] = weather_unique['date'].astype(str)\n",
    "weather_unique['hour'] = weather_unique['hour'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = trip_count.merge(weather_unique, on=['date', 'hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data[modeling_data['temp'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is null.\n",
    "modeling_data[modeling_data.isnull().any(axis=1)]['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuere engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = modeling_data[['start_station_id', 'date', 'hour_quarter', 'trip_count', 'is_workday',\n",
    "       'week_of_year', 'weekday', 'clouds_all', 'humidity',\n",
    "       'pressure', 'rain_1h', 'rain_3h', 'temp', 'temp_max', 'temp_min'\n",
    "                      , 'weather_main', 'wind_deg', 'wind_speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummmies_remove_original_col(df, cols):\n",
    "    for col in cols:\n",
    "        dummies_cols = pd.get_dummies(df[col])\n",
    "        df = pd.concat([df, dummies_cols], axis = 1)\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(data['weather_main'].str.get_dummies('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('weather_main', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hour_quarter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(data_train, data_test, lable_field='trip_count'):\n",
    "    X_train = data_train.drop(lable_field, axis=1)\n",
    "    y_train = data_train[lable_field]\n",
    "\n",
    "    X_test = data_test.drop(lable_field, axis=1)\n",
    "    y_test = data_test[lable_field]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_date = '2016-06-02'\n",
    "forecast_station_id = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[(data['date'] < forecast_date) & (data['start_station_id'] == forecast_station_id)]\n",
    "data_test = data[(data['date'] == forecast_date) & (data['start_station_id'] == forecast_station_id)]\n",
    "data_train = data_train[(data_train['hour_quarter'] >= 5) & (data_train['hour_quarter'] <= 23)]\n",
    "data_test = data_test[(data_test['hour_quarter'] >= 5) & (data_test['hour_quarter'] <= 23)]\n",
    "data_train = data_train.drop(['date', 'start_station_id'], axis=1)\n",
    "data_test = data_test.drop(['date', 'start_station_id'], axis=1)\n",
    "X_train, X_test, y_train, y_test = get_train_test_data(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "              'max_depth': range(3, 9),\n",
    "              'n_estimators': range(10, 300, 20),\n",
    "              'learning_rate': [0.01],\n",
    "              'gamma':[0.2],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bylevel':[0.8]\n",
    "             }\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model = GridSearchCV(xgb_model, param_grid, n_jobs=16, cv = 5)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(xgb_model.best_score_)\n",
    "print(xgb_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "clf1 = RandomForestRegressor(n_jobs=-1, max_depth=10,random_state=0)\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(r2_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "clf2 = xgb.XGBRegressor(n_estimators=400, max_depth=8, n_jobs=8,\n",
    "                            learning_rate=0.01, subsample=0.8, colsample_bylevel=0.8, seed=0,\n",
    "                             gamma=0.2)\n",
    "\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "y_pred = clf2.predict(X_test)\n",
    "print(r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(20, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(X_test['hour_quarter'], y_pred, 'r*')\n",
    "plt.plot(X_test['hour_quarter'], y_test, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_station_id_list = set(trip_count['start_station_id'].astype(int).unique())\n",
    "start_station_id_list.remove(0)\n",
    "\n",
    "# start_station_id_list = [458]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(start_station_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import datetime\n",
    "\n",
    "train_records_limit = 100\n",
    "forecast_start_date = '2016-05-12'\n",
    "forecast_future_days = 45\n",
    "forecast_date_range = [d.strftime(\"%Y-%m-%d\") for d in pd.date_range(start=forecast_start_date, periods=forecast_future_days)]\n",
    "\n",
    "r2_results = defaultdict(dict)\n",
    "\n",
    "\n",
    "for station_id in start_station_id_list:\n",
    "    for forecast_date in forecast_date_range:\n",
    "        data_train = data[(data['date'] < forecast_date) & (data['start_station_id'] == station_id)]\n",
    "        data_test = data[(data['date'] == forecast_date) & (data['start_station_id'] == station_id)]   \n",
    "        data_train = data_train[(data_train['hour_quarter'] >= 5) & (data_train['hour_quarter'] <= 23)]\n",
    "        data_test = data_test[(data_test['hour_quarter'] >= 5) & (data_test['hour_quarter'] <= 23)]\n",
    "        \n",
    "#         print(f\"data_train.shape: {data_train.shape}, data_test.shape: {data_test.shape}\")\n",
    "        if data_test['trip_count'].sum() < train_records_limit:\n",
    "            print(f\"Warning! station_id {station_id} test data trip count is{data_test.shape[0]}, less than {train_records_limit} limit!\")\n",
    "            continue\n",
    "            \n",
    "        data_train = data_train.drop(['date', 'start_station_id'], axis=1)\n",
    "        data_test = data_test.drop(['date', 'start_station_id'], axis=1)\n",
    "        X_train, X_test, y_train, y_test = get_train_test_data(data_train, data_test)\n",
    "\n",
    "        r2_result = -1\n",
    "        retry = 0\n",
    "        while(r2_result < 0 and retry < 5):\n",
    "            clf2 = xgb.XGBRegressor(n_estimators=400, max_depth=8, n_jobs=8,\n",
    "                            learning_rate=0.01, subsample=0.8, colsample_bylevel=0.8, seed=0,\n",
    "                             gamma=0.2)\n",
    "            clf2.fit(X_train, y_train)\n",
    "            y_pred = clf2.predict(X_test)\n",
    "            r2_result = r2_score(y_test,y_pred)\n",
    "            if r2_result < 0:\n",
    "                print(\"r2_result less than 0, retry \", retry)\n",
    "                retry += 1\n",
    "        \n",
    "        print(f\"station_id: {station_id}, forecast_date: {forecast_date}, r2: {r2_result}\")\n",
    "        r2_results[station_id][forecast_date] = r2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, date_r2_dict in r2_results.items():\n",
    "    r2_mean = np.array(list(date_r2_dict.values())).mean()\n",
    "    if r2_mean < 0.85:\n",
    "        print(f\"station_id: {station_id}, r2_mean: {r2_mean}\")\n",
    "        print(r2_results[station_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "station_r2_heatmap_dict = {}\n",
    "for station_id, date_r2_dict in r2_results.items():\n",
    "    station_r2_heatmap_dict[station_id] = date_r2_dict.values()\n",
    "    \n",
    "station_r2_heatmap_df = pd.DataFrame.from_dict(station_r2_heatmap_dict, orient='index')\n",
    "station_r2_heatmap_df.columns = forecast_date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.heatmap(ax=ax, data=station_r2_heatmap_df, vmin=0.25, vmax=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(date_r2_dict.values())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_mean_arr = []\n",
    "\n",
    "for station_id, date_r2_dict in r2_results.items():\n",
    "    r2_mean = np.array(list(date_r2_dict.values())).mean()\n",
    "    r2_mean_arr.append(r2_mean)\n",
    "    \n",
    "np.mean(r2_mean_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_date = '2016-06-18'\n",
    "forecast_station_id = 458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[(data['date'] < forecast_date) & (data['start_station_id'] == station_id)]\n",
    "data_test = data[(data['date'] == forecast_date) & (data['start_station_id'] == station_id)]\n",
    "\n",
    "print(\"data_train.shape:\", data_train.shape)\n",
    "\n",
    "\n",
    "data_train = data_train.drop(['date', 'start_station_id'], axis=1)\n",
    "data_test = data_test.drop(['date', 'start_station_id'], axis=1)\n",
    "X_train, X_test, y_train, y_test = get_train_test_data(data_train, data_test)\n",
    "\n",
    "clf2 = xgb.XGBRegressor(n_estimators=300, max_depth=8, n_jobs=8,\n",
    "                            learning_rate=0.01, subsample=0.8, colsample_bylevel=0.8, seed=0,\n",
    "                             gamma=0.2)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "y_pred = clf2.predict(X_test)\n",
    "r2_result = r2_score(y_test,y_pred) \n",
    "print(f\"station_id: {station_id}, forecast_date: {forecast_date}, r2: {r2_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(20, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(X_test['hour_quarter'], y_pred, 'r*')\n",
    "plt.plot(X_test['hour_quarter'], y_test, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "water",
   "language": "python",
   "name": "water"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
